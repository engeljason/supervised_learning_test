{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from pathlib import Path\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.metrics import classification_report"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "train_df = pd.read_csv(Path('Resources/Generator/2019loans.csv'))\r\n",
    "test_df = pd.read_csv(Path('Resources/Generator/2020Q1loans.csv'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Convert categorical data to numeric and separate target feature for training data\r\n",
    "ry = pd.get_dummies(train_df['target'])['high_risk']\r\n",
    "rtrimmed = train_df.drop('target', axis=1)\r\n",
    "rX = pd.get_dummies(rtrimmed)\r\n",
    "\r\n",
    "# Convert categorical data to numeric and separate target feature for testing data\r\n",
    "sy = pd.get_dummies(test_df['target'])['high_risk']\r\n",
    "strimmed = test_df.drop('target', axis=1)\r\n",
    "sX = pd.get_dummies(strimmed)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# test for missing dummy variables in sets\r\n",
    "missing = []\r\n",
    "for label in rX.columns:\r\n",
    "    if label not in sX.columns:\r\n",
    "        missing.append(label)\r\n",
    "print(f'Items in training but not testing: {missing}')\r\n",
    "# confirm only rdum has missing values\r\n",
    "print(f'Items in only one set: {set(rX.columns) ^ set(sX.columns)}')\r\n",
    "\r\n",
    "# add missing dummy variables to testing set\r\n",
    "for column in missing:\r\n",
    "    sX[column] = 0\r\n",
    "\r\n",
    "# confirm values are now symmetric\r\n",
    "print(f'Items missing after adjustment: {set(rX.columns) ^ set(sX.columns)}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Items in training but not testing: ['debt_settlement_flag_Y']\n",
      "Items in only one set: {'debt_settlement_flag_Y'}\n",
      "Items missing after adjustment: set()\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Train the Logistic Regression model on the unscaled data\r\n",
    "classifier = LogisticRegression(max_iter=20000)\r\n",
    "classifier.fit(rX, ry)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=20000)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def print_score(classifier, rX, ry, sX, sy):\r\n",
    "    print(f\"Training Score: {classifier.score(rX, ry)}\")\r\n",
    "    print(f\"Testing Score: {classifier.score(sX, sy)}\")\r\n",
    "    print(classification_report(sy, classifier.predict(sX)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Print metrics for the Logistic Regression model\r\n",
    "print_score(classifier, rX, ry, sX, sy)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Score: 0.7087848932676519\n",
      "Testing Score: 0.5652913653764355\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.78      0.64      2351\n",
      "           1       0.61      0.36      0.45      2351\n",
      "\n",
      "    accuracy                           0.57      4702\n",
      "   macro avg       0.58      0.57      0.55      4702\n",
      "weighted avg       0.58      0.57      0.55      4702\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\r\n",
    "# Observation\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "From the extremely high `max_iter` required to get the model to converge in the above cell, it is likely the linear regression is going to be overfitted to the training data  \r\n",
    "\r\n",
    "This is reflected in the testing score being much lower than the training score"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Train a Random Forest Classifier model \r\n",
    "classifier2 = RandomForestClassifier()\r\n",
    "classifier2.fit(rX,ry)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Print the model score\r\n",
    "print_score(classifier2, rX, ry, sX, sy)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Score: 1.0\n",
      "Testing Score: 0.6412165036154828\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.47      0.57      2351\n",
      "           1       0.61      0.81      0.69      2351\n",
      "\n",
      "    accuracy                           0.64      4702\n",
      "   macro avg       0.66      0.64      0.63      4702\n",
      "weighted avg       0.66      0.64      0.63      4702\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Scale the data\r\n",
    "scaler = StandardScaler()\r\n",
    "scaler.fit(sX)\r\n",
    "rX_scaled = scaler.transform(rX)\r\n",
    "sX_scaled = scaler.transform(sX)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# Train the Logistic Regression model on the scaled data and print the model score\r\n",
    "classifier3 = LogisticRegression(max_iter=2000)\r\n",
    "classifier3.fit(rX_scaled, ry)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=2000)"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# Print metrics for the Logistic Regression model\r\n",
    "print_score(classifier3, rX_scaled, ry, sX_scaled, sy)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Score: 0.7090311986863711\n",
      "Testing Score: 0.7547851977881752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76      2351\n",
      "           1       0.76      0.74      0.75      2351\n",
      "\n",
      "    accuracy                           0.75      4702\n",
      "   macro avg       0.75      0.75      0.75      4702\n",
      "weighted avg       0.75      0.75      0.75      4702\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Train a Random Forest Classifier model on the scaled data and print the model score\r\n",
    "classifier4 = RandomForestClassifier()\r\n",
    "classifier4.fit(rX_scaled,ry)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Print the model score\r\n",
    "print_score(classifier4, rX_scaled, ry, sX_scaled, sy)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Score: 1.0\n",
      "Testing Score: 0.6316461080391322\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.47      0.56      2351\n",
      "           1       0.60      0.79      0.68      2351\n",
      "\n",
      "    accuracy                           0.63      4702\n",
      "   macro avg       0.65      0.63      0.62      4702\n",
      "weighted avg       0.65      0.63      0.62      4702\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# compare Logistic Regression scores\r\n",
    "\r\n",
    "print('Unscaled Logistic Regression score')\r\n",
    "print_score(classifier, rX, ry, sX, sy)\r\n",
    "print('-'*10)\r\n",
    "print('Scaled Logistic Regression score')\r\n",
    "print_score(classifier3, rX_scaled, ry, sX_scaled, sy)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Unscaled Logistic Regression score\n",
      "Training Score: 0.7087848932676519\n",
      "Testing Score: 0.5652913653764355\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.78      0.64      2351\n",
      "           1       0.61      0.36      0.45      2351\n",
      "\n",
      "    accuracy                           0.57      4702\n",
      "   macro avg       0.58      0.57      0.55      4702\n",
      "weighted avg       0.58      0.57      0.55      4702\n",
      "\n",
      "----------\n",
      "Scaled Logistic Regression score\n",
      "Training Score: 0.7090311986863711\n",
      "Testing Score: 0.7547851977881752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76      2351\n",
      "           1       0.76      0.74      0.75      2351\n",
      "\n",
      "    accuracy                           0.75      4702\n",
      "   macro avg       0.75      0.75      0.75      4702\n",
      "weighted avg       0.75      0.75      0.75      4702\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# compare Random Forest scores\r\n",
    "\r\n",
    "print('Unscaled Random Forest score')\r\n",
    "print_score(classifier2, rX, ry, sX, sy)\r\n",
    "print('-'*10)\r\n",
    "print('Scaled Random Forest score')\r\n",
    "print_score(classifier4, rX_scaled, ry, sX_scaled, sy)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Unscaled Random Forest score\n",
      "Training Score: 1.0\n",
      "Testing Score: 0.6412165036154828\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.47      0.57      2351\n",
      "           1       0.61      0.81      0.69      2351\n",
      "\n",
      "    accuracy                           0.64      4702\n",
      "   macro avg       0.66      0.64      0.63      4702\n",
      "weighted avg       0.66      0.64      0.63      4702\n",
      "\n",
      "----------\n",
      "Scaled Random Forest score\n",
      "Training Score: 1.0\n",
      "Testing Score: 0.6316461080391322\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.47      0.56      2351\n",
      "           1       0.60      0.79      0.68      2351\n",
      "\n",
      "    accuracy                           0.63      4702\n",
      "   macro avg       0.65      0.63      0.62      4702\n",
      "weighted avg       0.65      0.63      0.62      4702\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\r\n",
    "# Observations\r\n",
    "\r\n",
    "Taking an order of magnitude fewer iterations to converge, the scaled version of the Logistic Regression performed markedly better than the unscaled version (high-risk f1-score of 75 vs 45)\r\n",
    "\r\n",
    "Surprisingly, the random forest models were not improved by scaling the data, and while the random forest did better than the logistic regression when unscaled, the scaled logistic regression did much better than either of the random forest models (75 vs 69 and 68). "
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.10 64-bit ('PythonData': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "interpreter": {
   "hash": "79264824c40396a64d10485446bbc394f17a77ecfe3bed33e1bfdf8fe75a4647"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}